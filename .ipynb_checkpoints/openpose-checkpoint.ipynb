{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = { \"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                \"Background\": 15 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoFile = \"./pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"./pose_iter_160000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./14.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 500, 3)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input image dimensions\n",
    "#inWidth = 255\n",
    "#inHeight = 255\n",
    "inWidth = 368\n",
    "inHeight = 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the frame to be fed to the network\n",
    "inpBlob = cv2.dnn.blobFromImage(image, 1.0/255, (inWidth, inHeight), (0,0,0), swapRB = False, crop = False)\n",
    "\n",
    "# Set the prepared object as the input blob of the network\n",
    "net.setInput(inpBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 받아오기\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 ID :  44 , H :  95 , W :  69\n"
     ]
    }
   ],
   "source": [
    "# output.shape[0] = 이미지 ID, [1] = 출력 맵의 높이, [2] = 너비\n",
    "H = output.shape[1]\n",
    "W = output.shape[2]\n",
    "print(\"이미지 ID : \", len(output[0]), \", H : \", output.shape[2], \", W : \",output.shape[3]) # 이미지 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키포인트 검출시 이미지에 그려줌\n",
    "points = []\n",
    "for i in range(0,15):\n",
    "    # 해당 신체부위 신뢰도 얻음.\n",
    "    probMap = output[0, i, :, :]\n",
    " \n",
    "    # global 최대값 찾기\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "    # 원래 이미지에 맞게 점 위치 변경\n",
    "    x = (inWidth * point[0]) / (W)\n",
    "    y = (inHeight * point[1]) / (H)\n",
    "\n",
    "    # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "    if prob > 0.1 :    \n",
    "        cv2.circle(image, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)       # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "        cv2.putText(image, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)\n",
    "\n",
    "cv2.imshow(\"Output-Keypoints\",image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 복사\n",
    "imageCopy = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]             # Head\n",
    "    partA = BODY_PARTS[partA]   # 0\n",
    "    partB = pair[1]             # Neck\n",
    "    partB = BODY_PARTS[partB]   # 1\n",
    "    \n",
    "    #print(partA,\" 와 \", partB, \" 연결\\n\")\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(imageCopy, points[partA], points[partB], (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Output-Keypoints\",imageCopy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoFile = \"./pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"./pose_iter_160000.caffemodel\"\n",
    "nPoints = 18\n",
    "POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"fightt1.jpg\")\n",
    "frameCopy = np.copy(frame)\n",
    "frameWidth = frame.shape[1]\n",
    "frameHeight = frame.shape[0]\n",
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "# input image dimensions for the network\n",
    "inWidth = 368\n",
    "inHeight = 368\n",
    "inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                          (0, 0, 0), swapRB=False, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken by network : 2.241\n"
     ]
    }
   ],
   "source": [
    "net.setInput(inpBlob)\n",
    "\n",
    "output = net.forward()\n",
    "print(\"time taken by network : {:.3f}\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = output.shape[2]\n",
    "W = output.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "\n",
    "for i in range(nPoints):\n",
    "    # confidence map of corresponding body's part.\n",
    "    probMap = output[0, i, :, :]\n",
    "\n",
    "    # Find global maxima of the probMap.\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "    \n",
    "    # Scale the point to fit on the original image\n",
    "    x = (frameWidth * point[0]) / W\n",
    "    y = (frameHeight * point[1]) / H\n",
    "\n",
    "    if prob > threshold : \n",
    "        cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Skeleton\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "        cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Output-Keypoints', frameCopy)\n",
    "cv2.imshow('Output-Skeleton', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('Output-Keypoints.jpg', frameCopy)\n",
    "cv2.imwrite('Output-Skeleton.jpg', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken : 8.327\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time taken : {:.3f}\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
